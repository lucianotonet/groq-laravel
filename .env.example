# Groq API Configuration
GROQ_API_KEY=your-api-key-here
GROQ_MODEL=llama-3.1-8b-instant
GROQ_API_BASE=https://api.groq.com/openai/v1
GROQ_TIMEOUT=30

# Cache Configuration
GROQ_CACHE_ENABLED=true
GROQ_CACHE_TTL=3600
GROQ_CACHE_KEY_PREFIX=groq_

# Model Options
GROQ_MAX_TOKENS=150
GROQ_TEMPERATURE=0.7
GROQ_TOP_P=1.0
GROQ_FREQUENCY_PENALTY=0
GROQ_PRESENCE_PENALTY=0
GROQ_N=1

# Rate Limiting
GROQ_RATE_LIMIT=60

# Vision Configuration
GROQ_VISION_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
GROQ_VISION_MAX_TOKENS=300

# Batch Processing
GROQ_BATCH_COMPLETION_WINDOW=5m
GROQ_BATCH_MAX_SIZE=20
GROQ_BATCH_AUTO_PROCESS=true

# Speech Configuration
GROQ_SPEECH_MODEL=playai-tts
GROQ_SPEECH_VOICE=Bryan-PlayAI
GROQ_SPEECH_FORMAT=wav